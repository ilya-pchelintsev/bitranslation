{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"transformer_learning_en_de.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"JRLhT_fpT8zG","colab_type":"code","outputId":"1926313d-c35b-4899-a9dd-93a524f03f7c","executionInfo":{"status":"ok","timestamp":1583483029853,"user_tz":-180,"elapsed":52295,"user":{"displayName":"Ivan Shkurak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gik54LHly-61U9sVo9d7MChRHfCxEDkbok5to2x=s64","userId":"03010652311617817707"}},"colab":{"base_uri":"https://localhost:8080/","height":437}},"source":["%%bash\n","git clone https://github.com/pytorch/fairseq\n","cd fairseq\n","pip install --editable ."],"execution_count":1,"outputs":[{"output_type":"stream","text":["Obtaining file:///content/fairseq\n","  Installing build dependencies: started\n","  Installing build dependencies: finished with status 'done'\n","  Getting requirements to build wheel: started\n","  Getting requirements to build wheel: finished with status 'done'\n","  Installing backend dependencies: started\n","  Installing backend dependencies: finished with status 'done'\n","    Preparing wheel metadata: started\n","    Preparing wheel metadata: finished with status 'done'\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (1.17.5)\n","Collecting sacrebleu\n","  Downloading https://files.pythonhosted.org/packages/45/31/1a135b964c169984b27fb2f7a50280fa7f8e6d9d404d8a9e596180487fd1/sacrebleu-1.4.3-py3-none-any.whl\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (0.29.15)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (2019.12.20)\n","Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (1.14.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (4.28.1)\n","Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu->fairseq==0.9.0) (3.6.6)\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/91/db/7bc703c0760df726839e0699b7f78a4d8217fdc9c7fcb1b51b39c5a22a4e/portalocker-1.5.2-py2.py3-none-any.whl\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq==0.9.0) (2.19)\n","Installing collected packages: portalocker, sacrebleu, fairseq\n","  Running setup.py develop for fairseq\n","Successfully installed fairseq portalocker-1.5.2 sacrebleu-1.4.3\n"],"name":"stdout"},{"output_type":"stream","text":["Cloning into 'fairseq'...\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"uF6t6qGvi6VV","colab_type":"text"},"source":["Кладем скрипты предпобработки и вашу модель по нужным папкам."]},{"cell_type":"code","metadata":{"id":"kIYUJRwsg_zk","colab_type":"code","outputId":"60501077-4740-4d43-855b-3e95d071e607","executionInfo":{"status":"ok","timestamp":1583483093606,"user_tz":-180,"elapsed":111055,"user":{"displayName":"Ivan Shkurak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gik54LHly-61U9sVo9d7MChRHfCxEDkbok5to2x=s64","userId":"03010652311617817707"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","!cp -r '/content/gdrive/My Drive/Bidir translation/data-bin'\\\n","    '/content/'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E5dp45Zs_6pM","colab_type":"code","colab":{}},"source":["!mkdir /content/gdrive/My\\ Drive/Bidir\\ translation/checkpoints/transformer_en_de"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oWAeDwCICekb","colab_type":"code","outputId":"621cc08d-26b7-4011-ae5d-33ae5fce5701","executionInfo":{"status":"ok","timestamp":1583419349838,"user_tz":-180,"elapsed":18986,"user":{"displayName":"Ivan Shkurak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gik54LHly-61U9sVo9d7MChRHfCxEDkbok5to2x=s64","userId":"03010652311617817707"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["%%bash\n","echo 'Cloning Moses github repository (for tokenization scripts)...'\n","git clone https://github.com/moses-smt/mosesdecoder.git\n","\n","echo 'Cloning Subword NMT repository (for BPE pre-processing)...'\n","git clone https://github.com/rsennrich/subword-nmt.git"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cloning Moses github repository (for tokenization scripts)...\n","Cloning Subword NMT repository (for BPE pre-processing)...\n"],"name":"stdout"},{"output_type":"stream","text":["Cloning into 'mosesdecoder'...\n","Cloning into 'subword-nmt'...\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"WPCmnCY8Cx8N","colab_type":"code","outputId":"0dcd2c43-525b-4b07-90ac-a10aefa9d38c","executionInfo":{"status":"ok","timestamp":1583483098331,"user_tz":-180,"elapsed":23355,"user":{"displayName":"Ivan Shkurak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gik54LHly-61U9sVo9d7MChRHfCxEDkbok5to2x=s64","userId":"03010652311617817707"}},"colab":{"base_uri":"https://localhost:8080/","height":269}},"source":["!pip install sacremoses"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n","\r\u001b[K     |▍                               | 10kB 26.6MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 29.7MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30kB 26.1MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40kB 18.2MB/s eta 0:00:01\r\u001b[K     |██                              | 51kB 15.8MB/s eta 0:00:01\r\u001b[K     |██▎                             | 61kB 15.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 71kB 15.3MB/s eta 0:00:01\r\u001b[K     |███                             | 81kB 15.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 92kB 15.3MB/s eta 0:00:01\r\u001b[K     |███▉                            | 102kB 16.5MB/s eta 0:00:01\r\u001b[K     |████▏                           | 112kB 16.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 122kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 133kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 143kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 153kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 163kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 174kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 184kB 16.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 194kB 16.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 204kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 215kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 225kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 235kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 245kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 256kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 266kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 276kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 286kB 16.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 296kB 16.5MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 307kB 16.5MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 317kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 327kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 337kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 348kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 358kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 368kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 378kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 389kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 399kB 16.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 409kB 16.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 419kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 430kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 440kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 450kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 460kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 471kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 481kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 491kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 501kB 16.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 512kB 16.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 522kB 16.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 532kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 542kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 552kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 563kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 573kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 583kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 593kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 604kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 614kB 16.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 624kB 16.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 634kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 645kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 655kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 665kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 675kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 686kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 696kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 706kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 716kB 16.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 727kB 16.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 737kB 16.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 747kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 757kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 768kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 778kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 788kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 798kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 808kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 819kB 16.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 829kB 16.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 839kB 16.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 849kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 860kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 870kB 16.5MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from sacremoses) (2019.12.20)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses) (0.14.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sacremoses) (4.28.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=0ea92c9a23d36222cf2c41005bfcf70ca9b038335eedad012505074fd1aad5bc\n","  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n","Successfully built sacremoses\n","Installing collected packages: sacremoses\n","Successfully installed sacremoses-0.0.38\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VfPjqWGUT_pU","colab_type":"code","outputId":"9b29c4b3-5024-4a1a-899c-fcfa9c45f4a1","executionInfo":{"status":"ok","timestamp":1583410985906,"user_tz":-180,"elapsed":107658,"user":{"displayName":"Ivan Shkurak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gik54LHly-61U9sVo9d7MChRHfCxEDkbok5to2x=s64","userId":"03010652311617817707"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!CUDA_VISIBLE_DEVICES=0 fairseq-train \\\n","    data-bin/iwslt17.tokenized.en-de \\\n","    --arch transformer_iwslt_de_en --share-decoder-input-output-embed \\\n","    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n","    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n","    --dropout 0.3 --weight-decay 0.0001 \\\n","    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n","    --max-tokens 4096 \\\n","    --eval-bleu \\\n","    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n","    --eval-bleu-detok moses \\\n","    --eval-bleu-remove-bpe \\\n","    --eval-bleu-print-samples \\\n","    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \\\n","    --save-dir /content/gdrive/My\\ Drive/Bidir\\ translation/checkpoints/transformer_en_de \\\n","    --save-interval\t5\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-03-06 08:29:59 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_iwslt_de_en', attention_dropout=0.0, best_checkpoint_metric='bleu', bpe=None, broadcast_buffers=False, bucket_cap_mb=25, clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt17.tokenized.en-de', dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=True, eval_bleu_args='{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', eval_bleu_detok='moses', eval_bleu_detok_args=None, eval_bleu_print_samples=True, eval_bleu_remove_bpe='@@ ', eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layer_wise_attention=False, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_token_positional_embeddings=False, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/content/gdrive/My Drive/Bidir translation/checkpoints/transformer_en_de', save_interval=5, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, source_lang=None, target_lang=None, task='translation', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001)\n","2020-03-06 08:29:59 | INFO | fairseq.tasks.translation | [en] dictionary: 6760 types\n","2020-03-06 08:29:59 | INFO | fairseq.tasks.translation | [de] dictionary: 8976 types\n","2020-03-06 08:29:59 | INFO | fairseq.data.data_utils | loaded 9030 examples from: data-bin/iwslt17.tokenized.en-de/valid.en-de.en\n","2020-03-06 08:29:59 | INFO | fairseq.data.data_utils | loaded 9030 examples from: data-bin/iwslt17.tokenized.en-de/valid.en-de.de\n","2020-03-06 08:29:59 | INFO | fairseq.tasks.translation | data-bin/iwslt17.tokenized.en-de valid en-de 9030 examples\n","2020-03-06 08:30:00 | INFO | fairseq_cli.train | TransformerModel(\n","  (encoder): TransformerEncoder(\n","    (embed_tokens): Embedding(6760, 512, padding_idx=1)\n","    (embed_positions): SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (2): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (3): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (4): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (5): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","  )\n","  (decoder): TransformerDecoder(\n","    (embed_tokens): Embedding(8976, 512, padding_idx=1)\n","    (embed_positions): SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (2): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (3): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (4): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (5): TransformerDecoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=1024, bias=True)\n","        (fc2): Linear(in_features=1024, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","  )\n",")\n","2020-03-06 08:30:00 | INFO | fairseq_cli.train | model transformer_iwslt_de_en, criterion LabelSmoothedCrossEntropyCriterion\n","2020-03-06 08:30:00 | INFO | fairseq_cli.train | num. model params: 39600128 (num. trained: 39600128)\n","2020-03-06 08:30:03 | INFO | fairseq_cli.train | training on 1 GPUs\n","2020-03-06 08:30:03 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None\n","2020-03-06 08:30:04 | INFO | fairseq.trainer | loaded checkpoint /content/gdrive/My Drive/Bidir translation/checkpoints/transformer_en_de/checkpoint_last.pt (epoch 1 @ 55160 updates)\n","2020-03-06 08:30:04 | INFO | fairseq.trainer | loading train data for epoch 1\n","2020-03-06 08:30:04 | INFO | fairseq.data.data_utils | loaded 198669 examples from: data-bin/iwslt17.tokenized.en-de/train.en-de.en\n","2020-03-06 08:30:04 | INFO | fairseq.data.data_utils | loaded 198669 examples from: data-bin/iwslt17.tokenized.en-de/train.en-de.de\n","2020-03-06 08:30:04 | INFO | fairseq.tasks.translation | data-bin/iwslt17.tokenized.en-de train en-de 198669 examples\n","epoch 002:   3% 35/1379 [00:12<08:23,  2.67it/s, loss=5.192, nll_loss=3.883, ppl=14.76, wps=1529.7, ups=0.42, wpb=3593.7, bsz=134.1, num_updates=55195, lr=0.000134602, gnorm=1.147, clip=0, oom=0, train_wall=33, wall=0]"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eN7Etnk1YcR8","colab_type":"code","colab":{}},"source":["fairseq-generate data-bin/iwslt17.tokenized.en-de \\\n","    --path /content/gdrive/My\\ Drive/Bidir\\ translation/checkpoints/transformer_en_de/checkpoint_best.pt \\\n","    --batch-size 128 --beam 5 --remove-bpe"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XeZT3jibGLk1","colab_type":"code","colab":{}},"source":["idx = 0\n","while True:\n","  idx += 1\n","  if idx > 100000000:\n","    idx = 0"],"execution_count":0,"outputs":[]}]}